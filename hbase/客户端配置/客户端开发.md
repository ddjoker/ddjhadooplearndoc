## 环境配置说明 hadoop2.7.3+ZooKeeper+hbase1.2.5 测试环境

#### 集群说明
1. eagle80 测试主服务器
2. eagle139 eagle140 测试分机

#### 版本说明
1. hadoop 2.7.3
2. hbase 1.2.5

#### 客户端环境
1. spring boot 1.5.9.RELEASE(可移除)
2.
```xml
<hadoop.version>2.6.0</hadoop.version>
<hbase.version>1.2.5</hbase.version>
<guava.version>18.0</guava.version>
```


## 开发遇上的实际问题.

1. 最少的配置是

  ```xml
  <dependency>
    <groupId>org.apache.hbase</groupId>
    <artifactId>hbase-common</artifactId>
    <version>${hbase.version}</version>
  </dependency>
  <dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-common</artifactId>
    <version>${hadoop.version}</version>
  </dependency>
  <dependency>
    <groupId>org.apache.hbase</groupId>
    <artifactId>hbase-client</artifactId>
    <version>${hbase.version}</version>
  </dependency>
  ```

2. `guava`的环境如果要配置的还千万与`hbase`的环境相吻合,否则会出现如下错误
  ```
  org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
  ```
  我选择了不配 ..

3. `hbase-site.xml` 一定要与线上环境完全相同,关键的就是`hbase.zookeeper.quorum`中的`value`必须完全相同才可以

  ```xml
  <property>
       <name>hbase.zookeeper.quorum</name>
       <value>eagle80,eagle139,eagle140</value>
   </property>
  ```
> 猜测是以 `域名/IP` 组合做了KEY.所以直接使用`IP`来适配是完全不可以的...
> 比如上面 `eagle80` 解析应该是作为 `eagle80/192.168.0.80` 作为key的..

4. 根据以上坑爹的配置,如果以域名作为`hbase.zookeeper.quorum`的配置的话,必须自行修改 `hosts` 文件.

  ```hosts
  ## windows C:\Windows\System32\drivers\etc\hosts
  ## linux /etc/hosts

  192.168.0.80 eagle80
  192.168.2.139 eagle139
  192.168.2.140 eagle140
  ```

  当然也可以用**局域网域名解析来解决**
5. 客户端`HADOOP`环境配置
   如果客户端没有配置HADOOP ,运行项目会出现两个错误
   1. `java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.`
      解决这个错误有三个办法
          1. `windows` 在环境变量中配置 `HADOOP_HOME=D:\package\dev\hadoop-2.7.3`;`linux` 配置在 `/etc/profile`等配置文件中加入 `export HADOOP_HOME=/package/dev/hadoop-2.7.3`

> 注: windows环境变量只能使用 `我的电脑->属性->高级系统设置->环境变量->新建`的方式添加,并在**打开的下一个命令行窗口**中生效.当然重新运行程序也可以.
> 注2 :linux环境变量在  `/etc/profile` 等文件中加入后,可以使用`source`这个修改的文件即时生效,**不会对已经打开的命令行窗口生效**.当然重新打开一个新shell窗口也可以.

          2. 在运行程序的命令/**IDE中的JVM环境变量**中添加`-Dhadoop.home.dir=D:\package\dev\hadoop-2.7.3`来声明`hadoop`环境.
          3. 在程序主入口/获取`connection` 链接之前`ConnectionFactory.createConnection(configuration);` 添加`System.setProperty("hadoop.home.dir","D:\\package\\dev\\hadoop-2.7.3");`
    2. `org.apache.hadoop.util.Shell - Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\bin\winutils.exe in the Hadoop binaries.`
    在`%HADOOP_HOME%/bin`目录下添加windows支持
    [windows环境支持文件(在hadoop的bin目录中)](./../../hadoop/Hadoop安装教程_单机/windows环境支持文件(在hadoop的bin目录中))
## 测试代码以及对应配置案例
 [pom.xml](./附件/pom.xml)

 [hbase-site.xml](.\附件\hbase-site.xml)

 [HBaseHelper.java](.\附件\java\main\HBaseHelper.java)

 [HBaseHelperDemo.java](.\附件\java\test\HBaseHelperDemo.java)
